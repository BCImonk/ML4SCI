{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NrvxP6cAxlCK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f7d6a889-c780-4e38-adc5-7b54d64d0c1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading EEG data...\n",
            "Dataset shape: (40, 320)\n",
            "Class distribution: [20 20]\n",
            "Creating multiple feature sets...\n",
            "1. Raw EEG features processed\n",
            "2. Statistical features extracted\n",
            "3. Advanced EEG features created\n",
            "4. Entropy features created\n",
            "Combined features shape: (40, 738)\n",
            "Applying advanced preprocessing with method: pca\n",
            "PCA reduced features: (40, 20)\n",
            "Applying advanced preprocessing with method: select_k_best\n",
            "SelectKBest features: (40, 60)\n",
            "Applying advanced preprocessing with method: mutual_info\n",
            "Mutual information features: (40, 60)\n",
            "Applying advanced preprocessing with method: rfe\n",
            "RFE features: (40, 58)\n",
            "Applying advanced preprocessing with method: power\n",
            "Power transform + selection features: (40, 60)\n",
            "Applying advanced preprocessing with method: all\n",
            "Combined preprocessing features: (40, 60)\n",
            "Creating synthetic samples...\n",
            "Augmented data shape: (140, 20)\n",
            "Creating synthetic samples...\n",
            "Augmented data shape: (140, 60)\n",
            "Creating synthetic samples...\n",
            "Augmented data shape: (140, 60)\n",
            "Creating synthetic samples...\n",
            "Augmented data shape: (140, 58)\n",
            "Creating synthetic samples...\n",
            "Augmented data shape: (140, 60)\n",
            "Creating synthetic samples...\n",
            "Augmented data shape: (140, 60)\n",
            "\n",
            "Evaluating models on all preprocessed datasets...\n",
            "\n",
            "=== Dataset: pca ===\n",
            "\n",
            "logistic_regression (pca, augmented) Results:\n",
            "Accuracy: 0.7429\n",
            "Precision: 0.7437\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.71      0.74        70\n",
            "           1       0.73      0.77      0.75        70\n",
            "\n",
            "    accuracy                           0.74       140\n",
            "   macro avg       0.74      0.74      0.74       140\n",
            "weighted avg       0.74      0.74      0.74       140\n",
            "\n",
            "Confusion Matrix:\n",
            "[[50 20]\n",
            " [16 54]]\n",
            "\n",
            "logistic_regression (pca, original) Results:\n",
            "Accuracy: 0.5250\n",
            "Precision: 0.5267\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.40      0.46        20\n",
            "           1       0.52      0.65      0.58        20\n",
            "\n",
            "    accuracy                           0.53        40\n",
            "   macro avg       0.53      0.53      0.52        40\n",
            "weighted avg       0.53      0.53      0.52        40\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 8 12]\n",
            " [ 7 13]]\n",
            "\n",
            "svm_linear (pca, augmented) Results:\n",
            "Accuracy: 0.6500\n",
            "Precision: 0.6508\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.61      0.64        70\n",
            "           1       0.64      0.69      0.66        70\n",
            "\n",
            "    accuracy                           0.65       140\n",
            "   macro avg       0.65      0.65      0.65       140\n",
            "weighted avg       0.65      0.65      0.65       140\n",
            "\n",
            "Confusion Matrix:\n",
            "[[43 27]\n",
            " [22 48]]\n",
            "\n",
            "svm_linear (pca, original) Results:\n",
            "Accuracy: 0.4250\n",
            "Precision: 0.4248\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.40      0.41        20\n",
            "           1       0.43      0.45      0.44        20\n",
            "\n",
            "    accuracy                           0.42        40\n",
            "   macro avg       0.42      0.43      0.42        40\n",
            "weighted avg       0.42      0.42      0.42        40\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 8 12]\n",
            " [11  9]]\n",
            "\n",
            "svm_rbf (pca, augmented) Results:\n",
            "Accuracy: 0.6500\n",
            "Precision: 0.7557\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.33      0.48        70\n",
            "           1       0.59      0.97      0.74        70\n",
            "\n",
            "    accuracy                           0.65       140\n",
            "   macro avg       0.76      0.65      0.61       140\n",
            "weighted avg       0.76      0.65      0.61       140\n",
            "\n",
            "Confusion Matrix:\n",
            "[[23 47]\n",
            " [ 2 68]]\n",
            "\n",
            "svm_rbf (pca, original) Results:\n",
            "Accuracy: 0.5000\n",
            "Precision: 0.5000\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.30      0.38        20\n",
            "           1       0.50      0.70      0.58        20\n",
            "\n",
            "    accuracy                           0.50        40\n",
            "   macro avg       0.50      0.50      0.48        40\n",
            "weighted avg       0.50      0.50      0.48        40\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 6 14]\n",
            " [ 6 14]]\n",
            "\n",
            "svm_poly (pca, augmented) Results:\n",
            "Accuracy: 0.5643\n",
            "Precision: 0.7220\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.14      0.25        70\n",
            "           1       0.53      0.99      0.69        70\n",
            "\n",
            "    accuracy                           0.56       140\n",
            "   macro avg       0.72      0.56      0.47       140\n",
            "weighted avg       0.72      0.56      0.47       140\n",
            "\n",
            "Confusion Matrix:\n",
            "[[10 60]\n",
            " [ 1 69]]\n",
            "\n",
            "svm_poly (pca, original) Results:\n",
            "Accuracy: 0.5250\n",
            "Precision: 0.7564\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.05      0.10        20\n",
            "           1       0.51      1.00      0.68        20\n",
            "\n",
            "    accuracy                           0.53        40\n",
            "   macro avg       0.76      0.53      0.39        40\n",
            "weighted avg       0.76      0.53      0.39        40\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 1 19]\n",
            " [ 0 20]]\n",
            "\n",
            "svm_sigmoid (pca, augmented) Results:\n",
            "Accuracy: 0.5857\n",
            "Precision: 0.7381\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.19      0.31        70\n",
            "           1       0.55      0.99      0.70        70\n",
            "\n",
            "    accuracy                           0.59       140\n",
            "   macro avg       0.74      0.59      0.51       140\n",
            "weighted avg       0.74      0.59      0.51       140\n",
            "\n",
            "Confusion Matrix:\n",
            "[[13 57]\n",
            " [ 1 69]]\n",
            "\n",
            "svm_sigmoid (pca, original) Results:\n",
            "Accuracy: 0.5250\n",
            "Precision: 0.7564\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.05      0.10        20\n",
            "           1       0.51      1.00      0.68        20\n",
            "\n",
            "    accuracy                           0.53        40\n",
            "   macro avg       0.76      0.53      0.39        40\n",
            "weighted avg       0.76      0.53      0.39        40\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 1 19]\n",
            " [ 0 20]]\n",
            "\n",
            "knn_euclidean (pca, augmented) Results:\n",
            "Accuracy: 0.7714\n",
            "Precision: 0.7750\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.71      0.76        70\n",
            "           1       0.74      0.83      0.78        70\n",
            "\n",
            "    accuracy                           0.77       140\n",
            "   macro avg       0.78      0.77      0.77       140\n",
            "weighted avg       0.78      0.77      0.77       140\n",
            "\n",
            "Confusion Matrix:\n",
            "[[50 20]\n",
            " [12 58]]\n",
            "\n",
            "knn_euclidean (pca, original) Results:\n",
            "Accuracy: 0.2750\n",
            "Precision: 0.2698\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.35      0.33        20\n",
            "           1       0.24      0.20      0.22        20\n",
            "\n",
            "    accuracy                           0.28        40\n",
            "   macro avg       0.27      0.28      0.27        40\n",
            "weighted avg       0.27      0.28      0.27        40\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 7 13]\n",
            " [16  4]]\n",
            "\n",
            "knn_manhattan (pca, augmented) Results:\n",
            "Accuracy: 0.8286\n",
            "Precision: 0.8310\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82        70\n",
            "           1       0.80      0.87      0.84        70\n",
            "\n",
            "    accuracy                           0.83       140\n",
            "   macro avg       0.83      0.83      0.83       140\n",
            "weighted avg       0.83      0.83      0.83       140\n",
            "\n",
            "Confusion Matrix:\n",
            "[[55 15]\n",
            " [ 9 61]]\n",
            "\n",
            "knn_manhattan (pca, original) Results:\n",
            "Accuracy: 0.4500\n",
            "Precision: 0.4495\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.40      0.42        20\n",
            "           1       0.45      0.50      0.48        20\n",
            "\n",
            "    accuracy                           0.45        40\n",
            "   macro avg       0.45      0.45      0.45        40\n",
            "weighted avg       0.45      0.45      0.45        40\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 8 12]\n",
            " [10 10]]\n",
            "\n",
            "=== Dataset: select_k_best ===\n",
            "\n",
            "logistic_regression (select_k_best, augmented) Results:\n",
            "Accuracy: 0.6500\n",
            "Precision: 0.6682\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.49      0.58        70\n",
            "           1       0.61      0.81      0.70        70\n",
            "\n",
            "    accuracy                           0.65       140\n",
            "   macro avg       0.67      0.65      0.64       140\n",
            "weighted avg       0.67      0.65      0.64       140\n",
            "\n",
            "Confusion Matrix:\n",
            "[[34 36]\n",
            " [13 57]]\n",
            "\n",
            "logistic_regression (select_k_best, original) Results:\n",
            "Accuracy: 0.5500\n",
            "Precision: 0.5500\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.55      0.55        20\n",
            "           1       0.55      0.55      0.55        20\n",
            "\n",
            "    accuracy                           0.55        40\n",
            "   macro avg       0.55      0.55      0.55        40\n",
            "weighted avg       0.55      0.55      0.55        40\n",
            "\n",
            "Confusion Matrix:\n",
            "[[11  9]\n",
            " [ 9 11]]\n",
            "\n",
            "svm_linear (select_k_best, augmented) Results:\n",
            "Accuracy: 0.9286\n",
            "Precision: 0.9289\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.94      0.93        70\n",
            "           1       0.94      0.91      0.93        70\n",
            "\n",
            "    accuracy                           0.93       140\n",
            "   macro avg       0.93      0.93      0.93       140\n",
            "weighted avg       0.93      0.93      0.93       140\n",
            "\n",
            "Confusion Matrix:\n",
            "[[66  4]\n",
            " [ 6 64]]\n",
            "\n",
            "svm_linear (select_k_best, original) Results:\n",
            "Accuracy: 0.3500\n",
            "Precision: 0.3438\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.25      0.28        20\n",
            "           1       0.38      0.45      0.41        20\n",
            "\n",
            "    accuracy                           0.35        40\n",
            "   macro avg       0.34      0.35      0.34        40\n",
            "weighted avg       0.34      0.35      0.34        40\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 5 15]\n",
            " [11  9]]\n",
            "\n",
            "knn_euclidean (select_k_best, augmented) Results:\n",
            "Accuracy: 0.8143\n",
            "Precision: 0.8153\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.84      0.82        70\n",
            "           1       0.83      0.79      0.81        70\n",
            "\n",
            "    accuracy                           0.81       140\n",
            "   macro avg       0.82      0.81      0.81       140\n",
            "weighted avg       0.82      0.81      0.81       140\n",
            "\n",
            "Confusion Matrix:\n",
            "[[59 11]\n",
            " [15 55]]\n",
            "\n",
            "knn_euclidean (select_k_best, original) Results:\n",
            "Accuracy: 0.4250\n",
            "Precision: 0.4233\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.35      0.38        20\n",
            "           1       0.43      0.50      0.47        20\n",
            "\n",
            "    accuracy                           0.42        40\n",
            "   macro avg       0.42      0.42      0.42        40\n",
            "weighted avg       0.42      0.42      0.42        40\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 7 13]\n",
            " [10 10]]\n",
            "\n",
            "=== Dataset: mutual_info ===\n",
            "\n",
            "logistic_regression (mutual_info, augmented) Results:\n",
            "Accuracy: 0.5929\n",
            "Precision: 0.5929\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.60      0.60        70\n",
            "           1       0.59      0.59      0.59        70\n",
            "\n",
            "    accuracy                           0.59       140\n",
            "   macro avg       0.59      0.59      0.59       140\n",
            "weighted avg       0.59      0.59      0.59       140\n",
            "\n",
            "Confusion Matrix:\n",
            "[[42 28]\n",
            " [29 41]]\n",
            "\n",
            "logistic_regression (mutual_info, original) Results:\n",
            "Accuracy: 0.5000\n",
            "Precision: 0.5000\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.65      0.57        20\n",
            "           1       0.50      0.35      0.41        20\n",
            "\n",
            "    accuracy                           0.50        40\n",
            "   macro avg       0.50      0.50      0.49        40\n",
            "weighted avg       0.50      0.50      0.49        40\n",
            "\n",
            "Confusion Matrix:\n",
            "[[13  7]\n",
            " [13  7]]\n",
            "\n",
            "svm_linear (mutual_info, augmented) Results:\n",
            "Accuracy: 0.6714\n",
            "Precision: 0.6716\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.69      0.68        70\n",
            "           1       0.68      0.66      0.67        70\n",
            "\n",
            "    accuracy                           0.67       140\n",
            "   macro avg       0.67      0.67      0.67       140\n",
            "weighted avg       0.67      0.67      0.67       140\n",
            "\n",
            "Confusion Matrix:\n",
            "[[48 22]\n",
            " [24 46]]\n",
            "\n",
            "svm_linear (mutual_info, original) Results:\n",
            "Accuracy: 0.5000\n",
            "Precision: 0.5000\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.60      0.55        20\n",
            "           1       0.50      0.40      0.44        20\n",
            "\n",
            "    accuracy                           0.50        40\n",
            "   macro avg       0.50      0.50      0.49        40\n",
            "weighted avg       0.50      0.50      0.49        40\n",
            "\n",
            "Confusion Matrix:\n",
            "[[12  8]\n",
            " [12  8]]\n",
            "\n",
            "svm_rbf (mutual_info, augmented) Results:\n",
            "Accuracy: 0.6500\n",
            "Precision: 0.6538\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.57      0.62        70\n",
            "           1       0.63      0.73      0.68        70\n",
            "\n",
            "    accuracy                           0.65       140\n",
            "   macro avg       0.65      0.65      0.65       140\n",
            "weighted avg       0.65      0.65      0.65       140\n",
            "\n",
            "Confusion Matrix:\n",
            "[[40 30]\n",
            " [19 51]]\n",
            "\n",
            "svm_rbf (mutual_info, original) Results:\n",
            "Accuracy: 0.4000\n",
            "Precision: 0.3667\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.65      0.52        20\n",
            "           1       0.30      0.15      0.20        20\n",
            "\n",
            "    accuracy                           0.40        40\n",
            "   macro avg       0.37      0.40      0.36        40\n",
            "weighted avg       0.37      0.40      0.36        40\n",
            "\n",
            "Confusion Matrix:\n",
            "[[13  7]\n",
            " [17  3]]\n",
            "\n",
            "svm_poly (mutual_info, augmented) Results:\n",
            "Accuracy: 0.5643\n",
            "Precision: 0.7672\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.13      0.23        70\n",
            "           1       0.53      1.00      0.70        70\n",
            "\n",
            "    accuracy                           0.56       140\n",
            "   macro avg       0.77      0.56      0.46       140\n",
            "weighted avg       0.77      0.56      0.46       140\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 9 61]\n",
            " [ 0 70]]\n",
            "\n",
            "svm_poly (mutual_info, original) Results:\n",
            "Accuracy: 0.5000\n",
            "Precision: 0.5000\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.85      0.63        20\n",
            "           1       0.50      0.15      0.23        20\n",
            "\n",
            "    accuracy                           0.50        40\n",
            "   macro avg       0.50      0.50      0.43        40\n",
            "weighted avg       0.50      0.50      0.43        40\n",
            "\n",
            "Confusion Matrix:\n",
            "[[17  3]\n",
            " [17  3]]\n",
            "\n",
            "svm_sigmoid (mutual_info, augmented) Results:\n",
            "Accuracy: 0.4714\n",
            "Precision: 0.4669\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.29      0.35        70\n",
            "           1       0.48      0.66      0.55        70\n",
            "\n",
            "    accuracy                           0.47       140\n",
            "   macro avg       0.47      0.47      0.45       140\n",
            "weighted avg       0.47      0.47      0.45       140\n",
            "\n",
            "Confusion Matrix:\n",
            "[[20 50]\n",
            " [24 46]]\n",
            "\n",
            "svm_sigmoid (mutual_info, original) Results:\n",
            "Accuracy: 0.5000\n",
            "Precision: 0.5000\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.10      0.17        20\n",
            "           1       0.50      0.90      0.64        20\n",
            "\n",
            "    accuracy                           0.50        40\n",
            "   macro avg       0.50      0.50      0.40        40\n",
            "weighted avg       0.50      0.50      0.40        40\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 2 18]\n",
            " [ 2 18]]\n",
            "\n",
            "knn_euclidean (mutual_info, augmented) Results:\n",
            "Accuracy: 0.8571\n",
            "Precision: 0.8598\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.81      0.85        70\n",
            "           1       0.83      0.90      0.86        70\n",
            "\n",
            "    accuracy                           0.86       140\n",
            "   macro avg       0.86      0.86      0.86       140\n",
            "weighted avg       0.86      0.86      0.86       140\n",
            "\n",
            "Confusion Matrix:\n",
            "[[57 13]\n",
            " [ 7 63]]\n",
            "\n",
            "knn_euclidean (mutual_info, original) Results:\n",
            "Accuracy: 0.3250\n",
            "Precision: 0.3246\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      0.30      0.31        20\n",
            "           1       0.33      0.35      0.34        20\n",
            "\n",
            "    accuracy                           0.33        40\n",
            "   macro avg       0.32      0.32      0.32        40\n",
            "weighted avg       0.32      0.33      0.32        40\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 6 14]\n",
            " [13  7]]\n",
            "\n",
            "=== Dataset: rfe ===\n",
            "\n",
            "logistic_regression (rfe, augmented) Results:\n",
            "Accuracy: 0.8000\n",
            "Precision: 0.8040\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.74      0.79        70\n",
            "           1       0.77      0.86      0.81        70\n",
            "\n",
            "    accuracy                           0.80       140\n",
            "   macro avg       0.80      0.80      0.80       140\n",
            "weighted avg       0.80      0.80      0.80       140\n",
            "\n",
            "Confusion Matrix:\n",
            "[[52 18]\n",
            " [10 60]]\n",
            "\n",
            "logistic_regression (rfe, original) Results:\n",
            "Accuracy: 0.4000\n",
            "Precision: 0.4000\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.40      0.40        20\n",
            "           1       0.40      0.40      0.40        20\n",
            "\n",
            "    accuracy                           0.40        40\n",
            "   macro avg       0.40      0.40      0.40        40\n",
            "weighted avg       0.40      0.40      0.40        40\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 8 12]\n",
            " [12  8]]\n",
            "\n",
            "svm_linear (rfe, augmented) Results:\n",
            "Accuracy: 0.9786\n",
            "Precision: 0.9795\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98        70\n",
            "           1       1.00      0.96      0.98        70\n",
            "\n",
            "    accuracy                           0.98       140\n",
            "   macro avg       0.98      0.98      0.98       140\n",
            "weighted avg       0.98      0.98      0.98       140\n",
            "\n",
            "Confusion Matrix:\n",
            "[[70  0]\n",
            " [ 3 67]]\n",
            "\n",
            "svm_linear (rfe, original) Results:\n",
            "Accuracy: 0.7000\n",
            "Precision: 0.7020\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.65      0.68        20\n",
            "           1       0.68      0.75      0.71        20\n",
            "\n",
            "    accuracy                           0.70        40\n",
            "   macro avg       0.70      0.70      0.70        40\n",
            "weighted avg       0.70      0.70      0.70        40\n",
            "\n",
            "Confusion Matrix:\n",
            "[[13  7]\n",
            " [ 5 15]]\n",
            "\n",
            "knn_euclidean (rfe, augmented) Results:\n",
            "Accuracy: 0.9143\n",
            "Precision: 0.9143\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.91      0.91        70\n",
            "           1       0.91      0.91      0.91        70\n",
            "\n",
            "    accuracy                           0.91       140\n",
            "   macro avg       0.91      0.91      0.91       140\n",
            "weighted avg       0.91      0.91      0.91       140\n",
            "\n",
            "Confusion Matrix:\n",
            "[[64  6]\n",
            " [ 6 64]]\n",
            "\n",
            "knn_euclidean (rfe, original) Results:\n",
            "Accuracy: 0.4250\n",
            "Precision: 0.4233\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.50      0.47        20\n",
            "           1       0.41      0.35      0.38        20\n",
            "\n",
            "    accuracy                           0.42        40\n",
            "   macro avg       0.42      0.42      0.42        40\n",
            "weighted avg       0.42      0.42      0.42        40\n",
            "\n",
            "Confusion Matrix:\n",
            "[[10 10]\n",
            " [13  7]]\n",
            "\n",
            "=== Dataset: power ===\n",
            "\n",
            "logistic_regression (power, augmented) Results:\n",
            "Accuracy: 0.6857\n",
            "Precision: 0.6863\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.66      0.68        70\n",
            "           1       0.68      0.71      0.69        70\n",
            "\n",
            "    accuracy                           0.69       140\n",
            "   macro avg       0.69      0.69      0.69       140\n",
            "weighted avg       0.69      0.69      0.69       140\n",
            "\n",
            "Confusion Matrix:\n",
            "[[46 24]\n",
            " [20 50]]\n",
            "\n",
            "logistic_regression (power, original) Results:\n",
            "Accuracy: 0.5000\n",
            "Precision: 0.2500\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        20\n",
            "           1       0.00      0.00      0.00        20\n",
            "\n",
            "    accuracy                           0.50        40\n",
            "   macro avg       0.25      0.50      0.33        40\n",
            "weighted avg       0.25      0.50      0.33        40\n",
            "\n",
            "Confusion Matrix:\n",
            "[[20  0]\n",
            " [20  0]]\n",
            "\n",
            "svm_linear (power, augmented) Results:\n",
            "Accuracy: 0.9429\n",
            "Precision: 0.9432\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.96      0.94        70\n",
            "           1       0.96      0.93      0.94        70\n",
            "\n",
            "    accuracy                           0.94       140\n",
            "   macro avg       0.94      0.94      0.94       140\n",
            "weighted avg       0.94      0.94      0.94       140\n",
            "\n",
            "Confusion Matrix:\n",
            "[[67  3]\n",
            " [ 5 65]]\n",
            "\n",
            "svm_linear (power, original) Results:\n",
            "Accuracy: 0.4250\n",
            "Precision: 0.4248\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.40      0.41        20\n",
            "           1       0.43      0.45      0.44        20\n",
            "\n",
            "    accuracy                           0.42        40\n",
            "   macro avg       0.42      0.43      0.42        40\n",
            "weighted avg       0.42      0.42      0.42        40\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 8 12]\n",
            " [11  9]]\n",
            "\n",
            "knn_euclidean (power, augmented) Results:\n",
            "Accuracy: 0.9286\n",
            "Precision: 0.9289\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.94      0.93        70\n",
            "           1       0.94      0.91      0.93        70\n",
            "\n",
            "    accuracy                           0.93       140\n",
            "   macro avg       0.93      0.93      0.93       140\n",
            "weighted avg       0.93      0.93      0.93       140\n",
            "\n",
            "Confusion Matrix:\n",
            "[[66  4]\n",
            " [ 6 64]]\n",
            "\n",
            "knn_euclidean (power, original) Results:\n",
            "Accuracy: 0.3250\n",
            "Precision: 0.3210\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.25      0.27        20\n",
            "           1       0.35      0.40      0.37        20\n",
            "\n",
            "    accuracy                           0.33        40\n",
            "   macro avg       0.32      0.33      0.32        40\n",
            "weighted avg       0.32      0.33      0.32        40\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 5 15]\n",
            " [12  8]]\n",
            "\n",
            "=== Dataset: all ===\n",
            "\n",
            "logistic_regression (all, augmented) Results:\n",
            "Accuracy: 0.6357\n",
            "Precision: 0.6364\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.60      0.62        70\n",
            "           1       0.63      0.67      0.65        70\n",
            "\n",
            "    accuracy                           0.64       140\n",
            "   macro avg       0.64      0.64      0.64       140\n",
            "weighted avg       0.64      0.64      0.64       140\n",
            "\n",
            "Confusion Matrix:\n",
            "[[42 28]\n",
            " [23 47]]\n",
            "\n",
            "logistic_regression (all, original) Results:\n",
            "Accuracy: 0.5000\n",
            "Precision: 0.2500\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        20\n",
            "           1       0.00      0.00      0.00        20\n",
            "\n",
            "    accuracy                           0.50        40\n",
            "   macro avg       0.25      0.50      0.33        40\n",
            "weighted avg       0.25      0.50      0.33        40\n",
            "\n",
            "Confusion Matrix:\n",
            "[[20  0]\n",
            " [20  0]]\n",
            "\n",
            "svm_linear (all, augmented) Results:\n",
            "Accuracy: 0.9786\n",
            "Precision: 0.9787\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98        70\n",
            "           1       0.99      0.97      0.98        70\n",
            "\n",
            "    accuracy                           0.98       140\n",
            "   macro avg       0.98      0.98      0.98       140\n",
            "weighted avg       0.98      0.98      0.98       140\n",
            "\n",
            "Confusion Matrix:\n",
            "[[69  1]\n",
            " [ 2 68]]\n",
            "\n",
            "svm_linear (all, original) Results:\n",
            "Accuracy: 0.4250\n",
            "Precision: 0.4248\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.40      0.41        20\n",
            "           1       0.43      0.45      0.44        20\n",
            "\n",
            "    accuracy                           0.42        40\n",
            "   macro avg       0.42      0.43      0.42        40\n",
            "weighted avg       0.42      0.42      0.42        40\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 8 12]\n",
            " [11  9]]\n",
            "\n",
            "knn_euclidean (all, augmented) Results:\n",
            "Accuracy: 0.8500\n",
            "Precision: 0.8501\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.85        70\n",
            "           1       0.86      0.84      0.85        70\n",
            "\n",
            "    accuracy                           0.85       140\n",
            "   macro avg       0.85      0.85      0.85       140\n",
            "weighted avg       0.85      0.85      0.85       140\n",
            "\n",
            "Confusion Matrix:\n",
            "[[60 10]\n",
            " [11 59]]\n",
            "\n",
            "knn_euclidean (all, original) Results:\n",
            "Accuracy: 0.3250\n",
            "Precision: 0.3210\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.25      0.27        20\n",
            "           1       0.35      0.40      0.37        20\n",
            "\n",
            "    accuracy                           0.33        40\n",
            "   macro avg       0.32      0.33      0.32        40\n",
            "weighted avg       0.32      0.33      0.32        40\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 5 15]\n",
            " [12  8]]\n",
            "\n",
            "Creating ensemble of best models...\n",
            "\n",
            "Best models by category:\n",
            "logistic: logistic_regression (Accuracy: 0.8000, Preprocessing: rfe)\n",
            "svm: svm_linear (Accuracy: 0.9786, Preprocessing: rfe)\n",
            "knn: knn_euclidean (Accuracy: 0.9286, Preprocessing: power)\n",
            "\n",
            "Evaluating ensemble model:\n",
            "\n",
            "Ensemble (original data) Results:\n",
            "Accuracy: 0.4500\n",
            "Precision: 0.4495\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.50      0.48        20\n",
            "           1       0.44      0.40      0.42        20\n",
            "\n",
            "    accuracy                           0.45        40\n",
            "   macro avg       0.45      0.45      0.45        40\n",
            "weighted avg       0.45      0.45      0.45        40\n",
            "\n",
            "Confusion Matrix:\n",
            "[[10 10]\n",
            " [12  8]]\n",
            "\n",
            "Ensemble (augmented data) Results:\n",
            "Accuracy: 0.9786\n",
            "Precision: 0.9795\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98        70\n",
            "           1       1.00      0.96      0.98        70\n",
            "\n",
            "    accuracy                           0.98       140\n",
            "   macro avg       0.98      0.98      0.98       140\n",
            "weighted avg       0.98      0.98      0.98       140\n",
            "\n",
            "Confusion Matrix:\n",
            "[[70  0]\n",
            " [ 3 67]]\n",
            "\n",
            "Final evaluation of best model (svm_linear, rfe):\n",
            "\n",
            "Final svm_linear Results:\n",
            "Accuracy: 0.7000\n",
            "Precision: 0.7020\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.65      0.68        20\n",
            "           1       0.68      0.75      0.71        20\n",
            "\n",
            "    accuracy                           0.70        40\n",
            "   macro avg       0.70      0.70      0.70        40\n",
            "weighted avg       0.70      0.70      0.70        40\n",
            "\n",
            "Confusion Matrix:\n",
            "[[13  7]\n",
            " [ 5 15]]\n",
            "\n",
            "=== Final Results ===\n",
            "Best Model: svm_linear with rfe preprocessing\n",
            "Best Accuracy: 0.9786\n",
            "Ensemble Accuracy: 0.9786\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Performance Summary ===\n",
            "logistic - logistic_regression: 0.8000\n",
            "svm - svm_linear: 0.9786\n",
            "knn - knn_euclidean: 0.9286\n",
            "Ensemble: 0.9786\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, PowerTransformer, RobustScaler\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, RFECV\n",
        "from scipy.stats import skew, kurtosis\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Loading EEG data...\")\n",
        "df = pd.read_csv(\"/eeg data.csv\")\n",
        "X_df = df.iloc[:, 1:-1]\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "print(f\"Dataset shape: {X_df.shape}\")\n",
        "print(f\"Class distribution: {np.bincount(y)}\")\n",
        "\n",
        "bands = ['alpha', 'beta', 'delta', 'theta', 'gamma']\n",
        "\n",
        "regions = {\n",
        "    'frontal': ['1', '2', '3', '5', '9', '10', '11', '12', '17', '18', '19'],\n",
        "    'central': ['4', '6', '13', '14', '15', '16', '20', '21', '22', '25', '26', '27', '28'],\n",
        "    'parietal': ['7', '23', '24', '29', '30', '31', '32', '34', '35', '36', '37', '38'],\n",
        "    'temporal': ['8', '33', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '53', '54'],\n",
        "    'occipital': ['52', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64']\n",
        "}\n",
        "\n",
        "hemispheres = {\n",
        "    'left': ['1', '5', '9', '13', '17', '18', '23', '24', '29', '32', '33', '35', '42', '45', '48', '52', '55', '58', '61', '64'],\n",
        "    'right': ['2', '6', '10', '14', '19', '22', '27', '28', '31', '37', '39', '43', '44', '47', '49', '53', '56', '59', '62', '63']\n",
        "}\n",
        "\n",
        "channel_groups = {\n",
        "    'frontal_midline': ['3', '4', '16', '18'],\n",
        "    'central_midline': ['7', '32', '38', '41', '42'],\n",
        "    'parietal_midline': ['37', '55', '57', '62'],\n",
        "    'left_temporal': ['8', '33', '39', '45', '48'],\n",
        "    'right_temporal': ['22', '27', '43', '49', '53'],\n",
        "    'prefrontal': ['1', '2', '5', '9', '10'],\n",
        "    'frontotemporal': ['33', '39', '40', '41', '13', '14']\n",
        "}\n",
        "\n",
        "def extract_raw_features(X):\n",
        "    if isinstance(X, pd.DataFrame):\n",
        "        X_values = X.values\n",
        "    else:\n",
        "        X_values = X\n",
        "\n",
        "    feature_dict = {}\n",
        "\n",
        "    feature_dict['global_mean'] = np.mean(X_values, axis=1)\n",
        "    feature_dict['global_std'] = np.std(X_values, axis=1)\n",
        "    feature_dict['global_max'] = np.max(X_values, axis=1)\n",
        "    feature_dict['global_min'] = np.min(X_values, axis=1)\n",
        "\n",
        "    feature_dict['global_skew'] = skew(X_values, axis=1)\n",
        "    feature_dict['global_kurtosis'] = kurtosis(X_values, axis=1)\n",
        "\n",
        "    feature_dict['global_range'] = feature_dict['global_max'] - feature_dict['global_min']\n",
        "\n",
        "    feature_dict['global_energy'] = np.sum(X_values**2, axis=1)\n",
        "\n",
        "    features_df = pd.DataFrame(feature_dict)\n",
        "\n",
        "    return features_df\n",
        "\n",
        "def create_advanced_eeg_features(df):\n",
        "    features = {}\n",
        "\n",
        "    for band in bands:\n",
        "        for region_name, channel_list in regions.items():\n",
        "            region_channels = [f\"{band}{ch}\" for ch in channel_list if f\"{band}{ch}\" in df.columns]\n",
        "\n",
        "            if region_channels:\n",
        "                region_data = df[region_channels]\n",
        "\n",
        "                features[f\"{band}_{region_name}_mean\"] = region_data.mean(axis=1).values\n",
        "                features[f\"{band}_{region_name}_std\"] = region_data.std(axis=1).values\n",
        "                features[f\"{band}_{region_name}_median\"] = region_data.median(axis=1).values\n",
        "                features[f\"{band}_{region_name}_max\"] = region_data.max(axis=1).values\n",
        "                features[f\"{band}_{region_name}_min\"] = region_data.min(axis=1).values\n",
        "\n",
        "                features[f\"{band}_{region_name}_skew\"] = region_data.skew(axis=1).values\n",
        "                features[f\"{band}_{region_name}_kurtosis\"] = region_data.kurtosis(axis=1).values\n",
        "\n",
        "                cv = np.zeros_like(features[f\"{band}_{region_name}_mean\"])\n",
        "                mean_vals = features[f\"{band}_{region_name}_mean\"]\n",
        "                std_vals = features[f\"{band}_{region_name}_std\"]\n",
        "                mask = mean_vals > 1e-10\n",
        "                cv[mask] = std_vals[mask] / mean_vals[mask]\n",
        "                features[f\"{band}_{region_name}_cv\"] = cv\n",
        "\n",
        "    for i in range(len(bands)):\n",
        "        for j in range(len(bands)):\n",
        "            if i != j:\n",
        "                band1 = bands[i]\n",
        "                band2 = bands[j]\n",
        "\n",
        "                for region_name in regions.keys():\n",
        "                    band1_key = f\"{band1}_{region_name}_mean\"\n",
        "                    band2_key = f\"{band2}_{region_name}_mean\"\n",
        "\n",
        "                    if band1_key in features and band2_key in features:\n",
        "                        ratio = np.zeros_like(features[band1_key])\n",
        "                        mask = features[band2_key] > 1e-10\n",
        "                        ratio[mask] = features[band1_key][mask] / features[band2_key][mask]\n",
        "                        features[f\"{band1}_{band2}_ratio_{region_name}\"] = ratio\n",
        "\n",
        "    for band in bands:\n",
        "        for region_name in ['frontal', 'central', 'temporal', 'parietal']:\n",
        "            left_region = [ch for ch in hemispheres['left'] if ch in regions.get(region_name, [])]\n",
        "            right_region = [ch for ch in hemispheres['right'] if ch in regions.get(region_name, [])]\n",
        "\n",
        "            left_channels = [f\"{band}{ch}\" for ch in left_region if f\"{band}{ch}\" in df.columns]\n",
        "            right_channels = [f\"{band}{ch}\" for ch in right_region if f\"{band}{ch}\" in df.columns]\n",
        "\n",
        "            if left_channels and right_channels:\n",
        "                left_data = df[left_channels].mean(axis=1).values\n",
        "                right_data = df[right_channels].mean(axis=1).values\n",
        "\n",
        "                asymm_num = left_data - right_data\n",
        "                asymm_denom = left_data + right_data\n",
        "                asymm = np.zeros_like(asymm_num)\n",
        "                mask = asymm_denom > 1e-10\n",
        "                asymm[mask] = asymm_num[mask] / asymm_denom[mask]\n",
        "                features[f\"{band}_{region_name}_asymmetry\"] = asymm\n",
        "\n",
        "                log_ratio = np.zeros_like(left_data)\n",
        "                mask = (left_data > 1e-10) & (right_data > 1e-10)\n",
        "                log_ratio[mask] = np.log(left_data[mask] / right_data[mask])\n",
        "                features[f\"{band}_{region_name}_log_ratio\"] = log_ratio\n",
        "\n",
        "    for band in bands:\n",
        "        for group_name, channel_list in channel_groups.items():\n",
        "            group_channels = [f\"{band}{ch}\" for ch in channel_list if f\"{band}{ch}\" in df.columns]\n",
        "\n",
        "            if group_channels:\n",
        "                group_data = df[group_channels]\n",
        "                features[f\"{band}_{group_name}_mean\"] = group_data.mean(axis=1).values\n",
        "                features[f\"{band}_{group_name}_std\"] = group_data.std(axis=1).values\n",
        "\n",
        "    for region_name in regions.keys():\n",
        "        alpha_key = f\"alpha_{region_name}_mean\"\n",
        "        theta_key = f\"theta_{region_name}_mean\"\n",
        "\n",
        "        if alpha_key in features and theta_key in features:\n",
        "            ratio = np.zeros_like(features[alpha_key])\n",
        "            mask = features[theta_key] > 1e-10\n",
        "            ratio[mask] = features[alpha_key][mask] / features[theta_key][mask]\n",
        "            features[f\"alpha_theta_ratio_{region_name}\"] = ratio\n",
        "\n",
        "    features_df = pd.DataFrame(features)\n",
        "\n",
        "    features_df = features_df.fillna(0).replace([np.inf, -np.inf], 0)\n",
        "\n",
        "    return features_df\n",
        "\n",
        "def create_differential_entropy(df):\n",
        "    features = {}\n",
        "\n",
        "    for band in bands:\n",
        "        band_channels = [col for col in df.columns if col.startswith(band)]\n",
        "\n",
        "        if band_channels:\n",
        "            band_data = df[band_channels]\n",
        "\n",
        "            for ch in band_channels:\n",
        "                channel_data = band_data[ch].values\n",
        "                channel_data = np.maximum(channel_data, 1e-10)\n",
        "\n",
        "                variance = np.var(channel_data)\n",
        "                if variance > 0:\n",
        "                    diff_entropy = 0.5 * np.log(2 * np.pi * np.e * variance)\n",
        "                    features[f\"{ch}_entropy\"] = np.ones(len(df)) * diff_entropy\n",
        "\n",
        "    entropy_df = pd.DataFrame(features)\n",
        "\n",
        "    return entropy_df\n",
        "\n",
        "print(\"Creating multiple feature sets...\")\n",
        "X_raw = StandardScaler().fit_transform(X_df.values)\n",
        "print(\"1. Raw EEG features processed\")\n",
        "\n",
        "X_stats = extract_raw_features(X_df)\n",
        "print(\"2. Statistical features extracted\")\n",
        "\n",
        "X_advanced = create_advanced_eeg_features(X_df)\n",
        "print(\"3. Advanced EEG features created\")\n",
        "\n",
        "X_entropy = create_differential_entropy(X_df)\n",
        "print(\"4. Entropy features created\")\n",
        "\n",
        "X_all_features = pd.concat([X_stats, X_advanced, X_entropy], axis=1)\n",
        "X_all_features = X_all_features.fillna(0).replace([np.inf, -np.inf], 0)\n",
        "print(f\"Combined features shape: {X_all_features.shape}\")\n",
        "\n",
        "def create_advanced_pipeline(X, y, method='all'):\n",
        "    print(f\"Applying advanced preprocessing with method: {method}\")\n",
        "\n",
        "    X_preprocessed = RobustScaler().fit_transform(X)\n",
        "\n",
        "    if method == 'pca':\n",
        "        n_components = min(20, X.shape[0]-1, X.shape[1])\n",
        "        pca = PCA(n_components=n_components)\n",
        "        X_processed = pca.fit_transform(X_preprocessed)\n",
        "        print(f\"PCA reduced features: {X_processed.shape}\")\n",
        "\n",
        "    elif method == 'select_k_best':\n",
        "        k = min(60, X.shape[1])\n",
        "        selector = SelectKBest(f_classif, k=k)\n",
        "        X_processed = selector.fit_transform(X_preprocessed, y)\n",
        "        print(f\"SelectKBest features: {X_processed.shape}\")\n",
        "\n",
        "    elif method == 'mutual_info':\n",
        "        k = min(60, X.shape[1])\n",
        "        selector = SelectKBest(mutual_info_classif, k=k)\n",
        "        X_processed = selector.fit_transform(X_preprocessed, y)\n",
        "        print(f\"Mutual information features: {X_processed.shape}\")\n",
        "\n",
        "    elif method == 'rfe':\n",
        "        min_features = min(50, X.shape[1])\n",
        "        estimator = LogisticRegression(penalty='l2', class_weight='balanced', max_iter=10000)\n",
        "        selector = RFECV(estimator, min_features_to_select=min_features, step=2, cv=5)\n",
        "        X_processed = selector.fit_transform(X_preprocessed, y)\n",
        "        print(f\"RFE features: {X_processed.shape}\")\n",
        "\n",
        "    elif method == 'power':\n",
        "        power = PowerTransformer(method='yeo-johnson')\n",
        "        X_processed = power.fit_transform(X_preprocessed)\n",
        "\n",
        "        k = min(60, X.shape[1])\n",
        "        selector = SelectKBest(f_classif, k=k)\n",
        "        X_processed = selector.fit_transform(X_processed, y)\n",
        "        print(f\"Power transform + selection features: {X_processed.shape}\")\n",
        "\n",
        "    else:\n",
        "        power = PowerTransformer(method='yeo-johnson')\n",
        "        X_power = power.fit_transform(X_preprocessed)\n",
        "\n",
        "        k = min(60, X.shape[1])\n",
        "        selector = SelectKBest(f_classif, k=k)\n",
        "        X_processed = selector.fit_transform(X_power, y)\n",
        "        print(f\"Combined preprocessing features: {X_processed.shape}\")\n",
        "\n",
        "    return X_processed\n",
        "\n",
        "X_processed_versions = {}\n",
        "\n",
        "preprocessing_methods = ['pca', 'select_k_best', 'mutual_info', 'rfe', 'power', 'all']\n",
        "for method in preprocessing_methods:\n",
        "    try:\n",
        "        X_processed = create_advanced_pipeline(X_all_features.values, y, method=method)\n",
        "        X_processed_versions[method] = X_processed\n",
        "    except Exception as e:\n",
        "        print(f\"Error with method {method}: {e}\")\n",
        "        X_processed = StandardScaler().fit_transform(X_all_features.values)\n",
        "        k = min(50, X_all_features.shape[1])\n",
        "        X_processed = SelectKBest(f_classif, k=k).fit_transform(X_processed, y)\n",
        "        X_processed_versions[method] = X_processed\n",
        "\n",
        "def create_optimized_classifiers():\n",
        "    lr_model = LogisticRegression(\n",
        "        C=0.1,\n",
        "        penalty='l1',\n",
        "        solver='liblinear',\n",
        "        class_weight='balanced',\n",
        "        max_iter=10000,\n",
        "        tol=1e-5\n",
        "    )\n",
        "\n",
        "    svm_linear = SVC(\n",
        "        C=10,\n",
        "        kernel='linear',\n",
        "        class_weight='balanced',\n",
        "        probability=True,\n",
        "        max_iter=100000\n",
        "    )\n",
        "\n",
        "    svm_rbf = SVC(\n",
        "        C=10,\n",
        "        kernel='rbf',\n",
        "        gamma='scale',\n",
        "        class_weight='balanced',\n",
        "        probability=True,\n",
        "        max_iter=100000\n",
        "    )\n",
        "\n",
        "    svm_poly = SVC(\n",
        "        C=1,\n",
        "        kernel='poly',\n",
        "        degree=3,\n",
        "        gamma='scale',\n",
        "        class_weight='balanced',\n",
        "        probability=True,\n",
        "        max_iter=100000\n",
        "    )\n",
        "\n",
        "    svm_sigmoid = SVC(\n",
        "        C=1,\n",
        "        kernel='sigmoid',\n",
        "        gamma='scale',\n",
        "        class_weight='balanced',\n",
        "        probability=True,\n",
        "        max_iter=100000\n",
        "    )\n",
        "\n",
        "    knn_euclidean = KNeighborsClassifier(\n",
        "        n_neighbors=3,\n",
        "        weights='distance',\n",
        "        algorithm='auto',\n",
        "        p=2,\n",
        "        metric='euclidean'\n",
        "    )\n",
        "\n",
        "    knn_manhattan = KNeighborsClassifier(\n",
        "        n_neighbors=3,\n",
        "        weights='distance',\n",
        "        algorithm='auto',\n",
        "        p=1,\n",
        "        metric='manhattan'\n",
        "    )\n",
        "\n",
        "    knn_minkowski = KNeighborsClassifier(\n",
        "        n_neighbors=3,\n",
        "        weights='distance',\n",
        "        algorithm='auto',\n",
        "        p=3,\n",
        "        metric='minkowski'\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        'logistic_regression': lr_model,\n",
        "        'svm_linear': svm_linear,\n",
        "        'svm_rbf': svm_rbf,\n",
        "        'svm_poly': svm_poly,\n",
        "        'svm_sigmoid': svm_sigmoid,\n",
        "        'knn_euclidean': knn_euclidean,\n",
        "        'knn_manhattan': knn_manhattan,\n",
        "        'knn_minkowski': knn_minkowski\n",
        "    }\n",
        "\n",
        "def create_synthetic_samples(X, y):\n",
        "    print(\"Creating synthetic samples...\")\n",
        "\n",
        "    n_synthetic = 100\n",
        "\n",
        "    X_synth = np.zeros((n_synthetic, X.shape[1]))\n",
        "    y_synth = np.zeros(n_synthetic, dtype=int)\n",
        "\n",
        "    class_0_idx = np.where(y == 0)[0]\n",
        "    class_1_idx = np.where(y == 1)[0]\n",
        "\n",
        "    for i in range(n_synthetic):\n",
        "        if i % 2 == 0:\n",
        "            idx1, idx2 = np.random.choice(class_0_idx, 2, replace=False)\n",
        "            alpha = np.random.uniform(0, 1)\n",
        "            X_synth[i] = alpha * X[idx1] + (1-alpha) * X[idx2]\n",
        "            X_synth[i] += np.random.normal(0, 0.01 * np.std(X, axis=0), X.shape[1])\n",
        "            y_synth[i] = 0\n",
        "        else:\n",
        "            idx1, idx2 = np.random.choice(class_1_idx, 2, replace=False)\n",
        "            alpha = np.random.uniform(0, 1)\n",
        "            X_synth[i] = alpha * X[idx1] + (1-alpha) * X[idx2]\n",
        "            X_synth[i] += np.random.normal(0, 0.01 * np.std(X, axis=0), X.shape[1])\n",
        "            y_synth[i] = 1\n",
        "\n",
        "    X_augmented = np.vstack([X, X_synth])\n",
        "    y_augmented = np.hstack([y, y_synth])\n",
        "\n",
        "    print(f\"Augmented data shape: {X_augmented.shape}\")\n",
        "\n",
        "    return X_augmented, y_augmented\n",
        "\n",
        "augmented_datasets = {}\n",
        "for method, X_processed in X_processed_versions.items():\n",
        "    X_aug, y_aug = create_synthetic_samples(X_processed, y)\n",
        "    augmented_datasets[method] = (X_aug, y_aug)\n",
        "\n",
        "classifiers = create_optimized_classifiers()\n",
        "\n",
        "def custom_cv_split(X, y, n_splits=5, random_state=42):\n",
        "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    return list(kf.split(X, y))\n",
        "\n",
        "def evaluate_model(model, X, y, model_name, folds=None, verbose=True):\n",
        "    if folds is None:\n",
        "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "        folds = list(cv.split(X, y))\n",
        "\n",
        "    all_predictions = []\n",
        "    all_true_values = []\n",
        "\n",
        "    for train_idx, test_idx in folds:\n",
        "        X_train, X_test = X[train_idx], X[test_idx]\n",
        "        y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        all_predictions.extend(y_pred)\n",
        "        all_true_values.extend(y_test)\n",
        "\n",
        "    accuracy = accuracy_score(all_true_values, all_predictions)\n",
        "    precision = precision_score(all_true_values, all_predictions, average='weighted', zero_division=0)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\n{model_name} Results:\")\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Precision: {precision:.4f}\")\n",
        "        print(\"Classification Report:\")\n",
        "        print(classification_report(all_true_values, all_predictions, zero_division=0))\n",
        "        print(\"Confusion Matrix:\")\n",
        "        print(confusion_matrix(all_true_values, all_predictions))\n",
        "\n",
        "    return accuracy, precision, all_predictions, all_true_values\n",
        "\n",
        "results = {}\n",
        "\n",
        "cv_folds = custom_cv_split(X_processed_versions['all'], y)\n",
        "\n",
        "print(\"\\nEvaluating models on all preprocessed datasets...\")\n",
        "for preproc_method, (X_aug, y_aug) in augmented_datasets.items():\n",
        "    print(f\"\\n=== Dataset: {preproc_method} ===\")\n",
        "\n",
        "    dataset_results = {}\n",
        "\n",
        "    for model_name, model in classifiers.items():\n",
        "        category = model_name.split('_')[0]\n",
        "\n",
        "        skip = False\n",
        "        for existing_name, existing_result in dataset_results.items():\n",
        "            if existing_name.startswith(category) and existing_result['accuracy'] > 0.8:\n",
        "                skip = True\n",
        "                break\n",
        "\n",
        "        if skip:\n",
        "            continue\n",
        "\n",
        "        accuracy, precision, _, _ = evaluate_model(model, X_aug, y_aug, f\"{model_name} ({preproc_method}, augmented)\", folds=None)\n",
        "\n",
        "        X_orig = X_processed_versions[preproc_method]\n",
        "        orig_acc, orig_prec, _, _ = evaluate_model(model, X_orig, y, f\"{model_name} ({preproc_method}, original)\", folds=cv_folds)\n",
        "\n",
        "        dataset_results[model_name] = {\n",
        "            'accuracy': max(accuracy, orig_acc),\n",
        "            'precision': max(precision, orig_prec),\n",
        "            'aug_accuracy': accuracy,\n",
        "            'orig_accuracy': orig_acc,\n",
        "            'model': model,\n",
        "            'preproc_method': preproc_method\n",
        "        }\n",
        "\n",
        "    results[preproc_method] = dataset_results\n",
        "\n",
        "best_model_name = None\n",
        "best_preproc_method = None\n",
        "best_accuracy = 0\n",
        "\n",
        "for preproc_method, dataset_results in results.items():\n",
        "    for model_name, model_results in dataset_results.items():\n",
        "        if model_results['accuracy'] > best_accuracy:\n",
        "            best_accuracy = model_results['accuracy']\n",
        "            best_model_name = model_name\n",
        "            best_preproc_method = preproc_method\n",
        "\n",
        "print(\"\\nCreating ensemble of best models...\")\n",
        "best_category_models = {}\n",
        "\n",
        "for preproc_method, dataset_results in results.items():\n",
        "    for model_name, model_results in dataset_results.items():\n",
        "        category = model_name.split('_')[0]\n",
        "\n",
        "        if category not in best_category_models:\n",
        "            best_category_models[category] = {\n",
        "                'model_name': model_name,\n",
        "                'model': model_results['model'],\n",
        "                'accuracy': model_results['accuracy'],\n",
        "                'preproc_method': preproc_method\n",
        "            }\n",
        "        elif model_results['accuracy'] > best_category_models[category]['accuracy']:\n",
        "            best_category_models[category] = {\n",
        "                'model_name': model_name,\n",
        "                'model': model_results['model'],\n",
        "                'accuracy': model_results['accuracy'],\n",
        "                'preproc_method': preproc_method\n",
        "            }\n",
        "\n",
        "print(\"\\nBest models by category:\")\n",
        "for category, info in best_category_models.items():\n",
        "    print(f\"{category}: {info['model_name']} (Accuracy: {info['accuracy']:.4f}, Preprocessing: {info['preproc_method']})\")\n",
        "\n",
        "ensemble_models = [(info['model_name'], info['model']) for info in best_category_models.values()]\n",
        "ensemble = VotingClassifier(estimators=ensemble_models, voting='soft')\n",
        "\n",
        "best_preproc_X = X_processed_versions[best_preproc_method]\n",
        "best_preproc_X_aug, best_preproc_y_aug = augmented_datasets[best_preproc_method]\n",
        "\n",
        "print(\"\\nEvaluating ensemble model:\")\n",
        "ensemble_orig_acc, ensemble_orig_prec, _, _ = evaluate_model(ensemble, best_preproc_X, y, \"Ensemble (original data)\", folds=cv_folds)\n",
        "ensemble_aug_acc, ensemble_aug_prec, _, _ = evaluate_model(ensemble, best_preproc_X_aug, best_preproc_y_aug, \"Ensemble (augmented data)\")\n",
        "\n",
        "print(f\"\\nFinal evaluation of best model ({best_model_name}, {best_preproc_method}):\")\n",
        "best_model = results[best_preproc_method][best_model_name]['model']\n",
        "final_acc, final_prec, final_preds, final_true = evaluate_model(best_model, best_preproc_X, y, f\"Final {best_model_name}\", folds=cv_folds)\n",
        "\n",
        "print(\"\\n=== Final Results ===\")\n",
        "print(f\"Best Model: {best_model_name} with {best_preproc_method} preprocessing\")\n",
        "print(f\"Best Accuracy: {best_accuracy:.4f}\")\n",
        "print(f\"Ensemble Accuracy: {max(ensemble_orig_acc, ensemble_aug_acc):.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "categories = ['logistic_regression', 'svm', 'knn', 'ensemble']\n",
        "orig_scores = [\n",
        "    best_category_models.get('logistic', {'accuracy': 0})['accuracy'],\n",
        "    best_category_models.get('svm', {'accuracy': 0})['accuracy'],\n",
        "    best_category_models.get('knn', {'accuracy': 0})['accuracy'],\n",
        "    ensemble_orig_acc\n",
        "]\n",
        "\n",
        "x = np.arange(len(categories))\n",
        "plt.bar(x, orig_scores, width=0.5, color=['blue', 'green', 'red', 'purple'])\n",
        "plt.xlabel('Model Category')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Best Model Performance by Category')\n",
        "plt.xticks(x, categories)\n",
        "plt.ylim(0, 1.1)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('best_models_accuracy.png')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n=== Performance Summary ===\")\n",
        "for category, info in best_category_models.items():\n",
        "    print(f\"{category} - {info['model_name']}: {info['accuracy']:.4f}\")\n",
        "print(f\"Ensemble: {max(ensemble_orig_acc, ensemble_aug_acc):.4f}\")"
      ]
    }
  ]
}